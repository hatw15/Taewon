{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2eBOFBAEjLq"
      },
      "outputs": [],
      "source": [
        "# Arc2Face 클론 & 디렉토리 이동\n",
        "!git clone https://github.com/foivospar/Arc2Face.git\n",
        "%cd Arc2Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "V2uAUpJXFDvZ"
      },
      "outputs": [],
      "source": [
        "# 1) numpy (1.23.x)\n",
        "%pip install \"numpy<1.24.0\"\n",
        "\n",
        "# 2) torch + torchvision (GPU 빌드)\n",
        "%pip install torch==2.0.1 torchvision==0.15.2 \\\n",
        "    -f https://download.pytorch.org/whl/cu118/torch_stable.html\n",
        "\n",
        "# 3) Arc2Face 요구사항\n",
        "%pip install diffusers==0.23.0 \\\n",
        "            transformers==4.34.1 \\\n",
        "            peft \\\n",
        "            accelerate \\\n",
        "            insightface \\\n",
        "            onnxruntime-gpu \\\n",
        "            gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Pjz5YDa2Fcgr"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "hf_hub_download(repo_id=\"FoivosPar/Arc2Face\", filename=\"arc2face/config.json\", local_dir=\"./models\")\n",
        "hf_hub_download(repo_id=\"FoivosPar/Arc2Face\", filename=\"arc2face/diffusion_pytorch_model.safetensors\", local_dir=\"./models\")\n",
        "hf_hub_download(repo_id=\"FoivosPar/Arc2Face\", filename=\"encoder/config.json\", local_dir=\"./models\")\n",
        "hf_hub_download(repo_id=\"FoivosPar/Arc2Face\", filename=\"encoder/pytorch_model.bin\", local_dir=\"./models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oIigiSExHUYs"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6DrEiKJmHVI9"
      },
      "outputs": [],
      "source": [
        "# Colab에서 실행\n",
        "!mkdir -p models/antelopev2\n",
        "!unzip \"/content/drive/MyDrive/antelopev2.zip\" -d models/antelopev2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q8au6NqDG8dT"
      },
      "outputs": [],
      "source": [
        "hf_hub_download(repo_id=\"FoivosPar/Arc2Face\", filename=\"arcface.onnx\", local_dir=\"./models/antelopev2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_u6-8zNFPGg"
      },
      "outputs": [],
      "source": [
        "%pip uninstall -y peft\n",
        "%pip install peft==0.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pExWyne7Baec"
      },
      "outputs": [],
      "source": [
        "# 1) Huggingface Hub 버전 고정 (cached_download + split_* 모두 포함)\n",
        "%pip install huggingface_hub==0.17.3\n",
        "\n",
        "# 2) Accelerate 버전도 호환되는 버전으로 고정\n",
        "%pip install accelerate==0.20.3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyCwQxaaHu4u"
      },
      "outputs": [],
      "source": [
        "import sys, os\n",
        "# Arc2Face 클론 경로에 맞게 변경\n",
        "sys.path.append(os.path.abspath(\"/content/Arc2Face\"))\n",
        "\n",
        "from diffusers import (\n",
        "    StableDiffusionPipeline,\n",
        "    UNet2DConditionModel,\n",
        "    DPMSolverMultistepScheduler,\n",
        ")\n",
        "\n",
        "from arc2face import CLIPTextModelWrapper, project_face_embs\n",
        "\n",
        "import torch\n",
        "from insightface.app import FaceAnalysis\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Arc2Face is built upon SD1.5\n",
        "# The repo below can be used instead of the now deprecated 'runwayml/stable-diffusion-v1-5'\n",
        "base_model = 'stable-diffusion-v1-5/stable-diffusion-v1-5'\n",
        "\n",
        "encoder = CLIPTextModelWrapper.from_pretrained(\n",
        "    'models', subfolder=\"encoder\", torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "unet = UNet2DConditionModel.from_pretrained(\n",
        "    'models', subfolder=\"arc2face\", torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "        base_model,\n",
        "        text_encoder=encoder,\n",
        "        unet=unet,\n",
        "        torch_dtype=torch.float16,\n",
        "        safety_checker=None\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTmC9TbfCF86"
      },
      "outputs": [],
      "source": [
        "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)\n",
        "pipeline = pipeline.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xysYthZqGvx3"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "# 원본 이미지 표시\n",
        "orig = Image.open('/content/Arc2Face/assets/examples/joacquin.png')\n",
        "\n",
        "# 최대 가로·세로를 256px로 줄이되 비율 유지\n",
        "orig_small = orig.copy()\n",
        "orig_small.thumbnail((256, 256))\n",
        "\n",
        "# 축소된 이미지 표시\n",
        "display(orig_small)\n",
        "\n",
        "app = FaceAnalysis(providers=[\"CUDAExecutionProvider\",\"CPUExecutionProvider\"])\n",
        "app.prepare(ctx_id=0, det_size=(640,640))\n",
        "\n",
        "img = np.array(Image.open('/content/Arc2Face/assets/examples/joacquin.png'))[:,:,::-1]\n",
        "\n",
        "faces = app.get(img)\n",
        "faces = sorted(faces, key=lambda x:(x['bbox'][2]-x['bbox'][0])*(x['bbox'][3]-x['bbox'][1]))[-1]  # select largest face (if more than one detected)\n",
        "id_emb = torch.tensor(faces['embedding'], dtype=torch.float16)[None].cuda()\n",
        "id_emb = id_emb/torch.norm(id_emb, dim=1, keepdim=True)   # normalize embedding\n",
        "id_emb = project_face_embs(pipeline, id_emb)    # pass through the encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvXI_Q6yEE9J"
      },
      "outputs": [],
      "source": [
        "num_images = 4\n",
        "images = pipeline(prompt_embeds=id_emb, num_inference_steps=25, guidance_scale=3.0, num_images_per_prompt=num_images).images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjBiAHFjtDEw"
      },
      "outputs": [],
      "source": [
        "# 셸에서 실행 → PEFT 제거\n",
        "%pip uninstall -y peft\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxkRUZj_ukXX"
      },
      "outputs": [],
      "source": [
        "# zero_emb 생성 (1×512 크기의 제로 벡터)\n",
        "zero_emb = torch.zeros((1, 512), dtype=torch.float16, device=\"cuda\")\n",
        "# project_face_embs 로 negative prompt embedding 생성\n",
        "neg_emb  = project_face_embs(pipeline, zero_emb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFeYDgqnGTgr"
      },
      "outputs": [],
      "source": [
        "# 1) Img2Img 파이프라인 준비\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "from torch import Generator\n",
        "from IPython.display import display\n",
        "\n",
        "img2img = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "    base_model,\n",
        "    text_encoder=encoder,\n",
        "    unet=unet,\n",
        "    scheduler=pipeline.scheduler,\n",
        "    torch_dtype=torch.float16\n",
        ").to(\"cuda\")\n",
        "\n",
        "# 2) 호출 시 image=init 으로 넘겨야 init 이미지가 제대로 들어감\n",
        "from torch import Generator\n",
        "gen = Generator(\"cuda\").manual_seed(1234)\n",
        "init = orig.resize((512,512))\n",
        "\n",
        "outputs = img2img(\n",
        "    image                   = init,\n",
        "    prompt_embeds           = id_emb,\n",
        "    negative_prompt_embeds  = neg_emb,\n",
        "    strength                = 0.3,\n",
        "    num_inference_steps     = 50,\n",
        "    guidance_scale          = 7.5,\n",
        "    num_images_per_prompt   = 4,\n",
        "    generator               = gen\n",
        ")\n",
        "\n",
        "# 3) 결과 표시\n",
        "for img in outputs.images:\n",
        "    img.thumbnail((256,256))\n",
        "    display(img)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}